{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rondi91/BISINDO/blob/main/8_BISINDO_HARI_97.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUT_L6bjOu_B"
      },
      "source": [
        "# **1.PREPARING THE WORKSPACE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miqMSoFhziVS"
      },
      "source": [
        "## 1.1 Mount Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Si3sOwi7e06"
      },
      "outputs": [],
      "source": [
        "# 1.1 Mount Google Drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG-5g4RvdQ0H"
      },
      "outputs": [],
      "source": [
        "# Tensorflow version\n",
        "import tensorflow as tf \n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Isizxnjz7GH"
      },
      "source": [
        "## 1.2 Prepare & Clone Template TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDkIsATInS0C"
      },
      "outputs": [],
      "source": [
        "\n",
        "# buat folder project baru \n",
        "NEW_folder_work = '23.BISINDO_NAMA_HARI'\n",
        "# buat base_url root\n",
        "BASE_PATH = '/content/gdrive/MyDrive/'+NEW_folder_work+'/Tensorflow'\n",
        "\n",
        "# Clone template Train TFOD\n",
        "%cd /content/gdrive/MyDrive/\n",
        "!mkdir {NEW_folder_work}\n",
        "%cd /content/gdrive/MyDrive/{NEW_folder_work}\n",
        "!git clone https://github.com/rondi91/Tensorflow.git\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **1.3 Set Up Variable Path**"
      ],
      "metadata": {
        "id": "JnimmlyE_nwA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1crrus6pETIX"
      },
      "outputs": [],
      "source": [
        "# Set Up Variable Path\n",
        "\n",
        "NUM_STEPS = 2000\n",
        "LR_TOTAL_STEPS =100000\n",
        "BATCH_SIZE=64\n",
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet_'           #folder Train project\n",
        "OUTPUT_MODEL= 'my_ssd_mobnet_'+ str(NUM_STEPS)                     #OUTPUT MODEL TRAIN\n",
        "\n",
        "CUSTOM_MODEL_NAME+ str(NUM_STEPS)\n",
        "WORKSPACE_PATH = BASE_PATH+ '/workspace'\n",
        "SCRIPTS_PATH =  WORKSPACE_PATH+'/scripts'\n",
        "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
        "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
        "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
        "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
        "EXPORTED_MODELS = WORKSPACE_PATH+'/exported-models'\n",
        "\n",
        "# my_ssd_mobnet5_100batch_5k\n",
        "\n",
        "#APIMODEL_PATH = WORKSPACE_PATH+ 'Tensorflow/models'\n",
        "#CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
        "#CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_resnet101_v1_fpn/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GlkGq-wG_XM"
      },
      "source": [
        "# **2.Instalation TFOD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kMlXyHFH2_P"
      },
      "source": [
        "## **2.1 Install Object Detection**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOQTtIgac4Se"
      },
      "outputs": [],
      "source": [
        "# Clone the tensorflow models git repository\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P297VQSGdhq3"
      },
      "outputs": [],
      "source": [
        "# Install TensorFlow Object Detection API\n",
        "\n",
        "%cd models/research\n",
        "\n",
        "# Compile protos.\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Install TensorFlow Object Detection API.\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install --use-feature=in-tree-build ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byU6pGafZr3A"
      },
      "outputs": [],
      "source": [
        "!cp {ANNOTATION_PATH+'/arial.ttf'} /usr/share/fonts/truetype\n",
        "!cp {ANNOTATION_PATH+'/arial.ttf'} /usr/local/lib/python3.7/dist-packages/object_detection/utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XRFTH9BIBVT"
      },
      "source": [
        "## **2.2 Test the model builder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpasmWV7dpRf"
      },
      "outputs": [],
      "source": [
        "#Test Instalation objec detection\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcVsujyHozqE"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r59uBw2jHKK2"
      },
      "source": [
        "### **finish instalation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL2bbe8nhDc6"
      },
      "source": [
        "#  **3.Preprocessing Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv0pIFhUKFjW"
      },
      "source": [
        "##  3.1 Clone Dataset Image "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDYCkXj8x1_F"
      },
      "outputs": [],
      "source": [
        "#Clone dataset image \n",
        "\n",
        "#cd into tensorflow/workspace\n",
        "%cd {BASE_PATH}/workspace/\n",
        "\n",
        "!git clone https://github.com/rondi91/images.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTdhFgZPnxdX"
      },
      "source": [
        "## **3.2 Create the CSV files and the \"label_map.pbtxt\" file**\n",
        "\n",
        "Current working directory is /mydrive/customTF2/data/\n",
        "\n",
        "Run xml_to_csv script below to create ***test_labels.csv*** and ***train_labels.csv***\n",
        "\n",
        "This also creates the ***label_map.pbtxt*** file using the classes mentioned in the xml files. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmfXKo3in3VV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "%cd {IMAGE_PATH}\n",
        "\n",
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text  ,   \n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "for label_path in ['ALL_DATASET']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{ANNOTATION_PATH}/{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "label_map_path = os.path.join(ANNOTATION_PATH+\"/label_map.pbtxt\")\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n",
        "    print('Successfully created label_map.pbtxt ')    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcb3SAHB6Ntc"
      },
      "source": [
        "### optional CEK DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yznxVK0j6NDX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(ANNOTATION_PATH+\"/ALL_DATASET.csv\")\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJdMupjk7iiL"
      },
      "outputs": [],
      "source": [
        "data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b-4m6Wl8HUt"
      },
      "outputs": [],
      "source": [
        "jml_class=data['class'].drop_duplicates().count()\n",
        "# class_name=data['class'].drop_duplicates()\n",
        "class_name=data.groupby('class')['class'].count()\n",
        "\n",
        "print('======class name ============')\n",
        "print(class_name)\n",
        "print('======class total =====')\n",
        "print(jml_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY1aJiBYre0y"
      },
      "source": [
        "## **3.3 SPLIT & TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4u2utW_rbLD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%cd {ANNOTATION_PATH}\n",
        "data_all= pd.read_csv(ANNOTATION_PATH+'/ALL_DATASET.csv')\n",
        "\n",
        "X=data_all.drop('class', axis=1)\n",
        "y=data_all['class']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1010)\n",
        "\n",
        "y_train=pd.DataFrame(y_train)\n",
        "y_test=pd.DataFrame(y_test)\n",
        "\n",
        "data_train=pd.merge(X_train,y_train,left_index=True,right_index=True)\n",
        "data_test=pd.merge(X_test,y_test,left_index=True,right_index=True)\n",
        "\n",
        "data_train.to_csv('train.csv')\n",
        "print('Successfully created train.csv ')\n",
        "data_test.to_csv('test.csv')\n",
        "print('Successfully created test.csv ') \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suaq5Be0D2p6"
      },
      "outputs": [],
      "source": [
        "print('dimensi train.csv ')\n",
        "train = pd.read_csv(ANNOTATION_PATH+\"/train.csv\")\n",
        "train.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcQIRpQ0ELih"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv(ANNOTATION_PATH+\"/test.csv\")\n",
        "test.shape "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUZwn-wUoic1"
      },
      "source": [
        "## 3.4 GENERATE TF RECORD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RG3dLYUxNZt"
      },
      "outputs": [],
      "source": [
        "#Usage:  \n",
        "#!python generate_tfrecord.py output.csv output_pb.txt /path/to/images output.tfrecords\n",
        "%cd {ANNOTATION_PATH}\n",
        "#For train.record\n",
        "!python {SCRIPTS_PATH}/generate_tfrecord.py  train.csv  label_map.pbtxt {IMAGE_PATH}/ALL_DATASET/ train.record\n",
        "\n",
        "#For test.record\n",
        "!python {SCRIPTS_PATH}/generate_tfrecord.py  test.csv  label_map.pbtxt {IMAGE_PATH}/ALL_DATASET/ test.record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX3VCP9HJzTL"
      },
      "source": [
        "NOTE:\n",
        "\n",
        "If you haven't downloaded any pre-trained model yet, go back to Step 1 and finish downloading any pre-trained model of your choice.\n",
        "\n",
        "We are almost ready to start our model training, just a few more steps before we start our model training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDZd_WY_gLJ3"
      },
      "source": [
        "# **4.BUILD MODEL PROCESS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVMlimur9J-l"
      },
      "source": [
        "## 4.1 Download TF Models Pretrained Models from Tensorflow Model Zoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v1bn5hd8bG2"
      },
      "outputs": [],
      "source": [
        "# Step 6 Download TF Models Pretrained Models from Tensorflow Model Zoo\n",
        "\n",
        "\n",
        "# download Pretrained Models\n",
        "!wget -O {PRETRAINED_MODEL_PATH}/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "# ekstrak file to Pretraine models dir\n",
        "!cd {PRETRAINED_MODEL_PATH} && tar -zxvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxtDpxYd-Jna"
      },
      "outputs": [],
      "source": [
        "# 3.5.1 Copy Model Config to Training Folder\n",
        "!mkdir {MODEL_PATH +'/'+CUSTOM_MODEL_NAME}\n",
        "!cp {PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'} {MODEL_PATH+'/'+CUSTOM_MODEL_NAME}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiB7Csr09_nM"
      },
      "source": [
        "## 4.2 Setting  Config Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJLJGxR1-lgm"
      },
      "outputs": [],
      "source": [
        "# 3.5.2 Update Config For Transfer Learning\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YMQl7hD-qVX"
      },
      "outputs": [],
      "source": [
        "#3.5.3 show config pipeline\n",
        "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'\n",
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BV0MVXim-2zK"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2utuiWQx-7_L"
      },
      "outputs": [],
      "source": [
        "#3.5.4 Set config pipeline\n",
        "pipeline_config.model.ssd.num_classes = jml_class\n",
        "pipeline_config.train_config.batch_size = BATCH_SIZE\n",
        "pipeline_config.train_config.num_steps = NUM_STEPS\n",
        "pipeline_config.train_config.optimizer.momentum_optimizer.learning_rate.cosine_decay_learning_rate.total_steps = LR_TOTAL_STEPS\n",
        "pipeline_config.train_config.fine_tune_checkpoint = PRETRAINED_MODEL_PATH+'/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0'\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/train.record']\n",
        "pipeline_config.eval_input_reader[0].label_map_path = ANNOTATION_PATH + '/label_map.pbtxt'\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [ANNOTATION_PATH + '/test.record']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm3OVy5z-_A_"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9em1L8xCyC-k"
      },
      "outputs": [],
      "source": [
        "#3.5.5 show config pipeline setelah disetting\n",
        "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'\n",
        "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
        "config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql7XBP2VOhcV"
      },
      "source": [
        "Step 12- Copying some files\n",
        "\n",
        "\n",
        "*   Copy the \"model_main_tf2.py\" file from   \"TensorFlow\\models\\research\\object_detection\" and paste it into training_demo. We will need this file for training the model.\n",
        "\n",
        "*   Copy the \"exporter_main_v2.py\" file from \"TensorFlow\\models\\research\\object_detection\" and paste it into training_demo.\n",
        "We will need this file to export the trained model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q5vNzgCJNDa"
      },
      "source": [
        "Step 13- Configure the pipeline file.\n",
        "\n",
        "Refer the mentioned [Medium article](https://medium.com/@nisargkapkar/tensorflow-2-object-detection-api-with-google-colab-b2af171e81cc?source=friends_link&sk=0bb205df0e1c29a2e78c28671ddf4494) for more details!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlYkEJ5ez-XF"
      },
      "outputs": [],
      "source": [
        "#Reusing TensorBoard on port 6006 (pid 554)\n",
        "!kill 554"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngritkBjyETx"
      },
      "source": [
        "# **5.MODEL EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JISAAfK-inS"
      },
      "outputs": [],
      "source": [
        "#start the Tensorboard\n",
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir={MODEL_PATH +'/'+CUSTOM_MODEL_NAME}\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir=models/[name_of_pre-trained-model_you_downloaded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLN661EgVJg8"
      },
      "outputs": [],
      "source": [
        "# Reinstal OpenCV\n",
        "!pip uninstall opencv-python -y\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmHepMfTV6Q_"
      },
      "outputs": [],
      "source": [
        "#Install DNN library \n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4sC51Drys_w"
      },
      "source": [
        "## 4.3 Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFLP5SUS-vYa"
      },
      "outputs": [],
      "source": [
        "# Train the model.\n",
        "%cd {BASE_PATH}\n",
        "#run the cell to start model training \n",
        "\n",
        "!python model_main_tf2.py --model_dir={MODEL_PATH +'/'+CUSTOM_MODEL_NAME} --pipeline_config_path={MODEL_PATH +'/'+CUSTOM_MODEL_NAME}/pipeline.config\n",
        "#!python model_main_tf2.py --model_dir=workspace/models/my_ssd_mobnet2 --pipeline_config_path=workspace/models/my_ssd_mobnet2/pipeline.config\n",
        "# !python model_main_tf2.py --model_dir=models/[name_of_pre-trained-model_you_downloaded] --pipeline_config_path=models/[name_of_pre-trained-model_you_downloaded]/pipeline.config"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.4 compress model**"
      ],
      "metadata": {
        "id": "1XoeuDURnZyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kompress model\n",
        "%cd {MODEL_PATH}\n",
        "!zip -r {OUTPUT_MODEL}\"TRAIN_HARI.zip\" {CUSTOM_MODEL_NAME}"
      ],
      "metadata": {
        "id": "5sRhzb46m7rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTQ7Fd4k4H0P"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCmWC2Ae8DjW"
      },
      "source": [
        "Congratulations! You have finished model training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_YEdVTnYbEI"
      },
      "source": [
        "# **6.Export Trained Model.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_MODEL"
      ],
      "metadata": {
        "id": "cXVMU05pnzHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDSirOAQ-0sy"
      },
      "outputs": [],
      "source": [
        "#Step 12- Export the Trained Model.\n",
        "%cd {BASE_PATH}\n",
        "#run the cell to start model training \n",
        "#!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path {BASE_PATH}/workspace/models/my_ssd_mobnet2/pipeline.config --trained_checkpoint_dir /content/gdrive/MyDrive/3.gesture_bahasa_isyarat/Tensorflow/workspace/models/my_ssd_mobnet2 --output_directory workspace/exported-models/MYMODELSSD4\n",
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path {MODEL_PATH +'/'+CUSTOM_MODEL_NAME}/pipeline.config --trained_checkpoint_dir {MODEL_PATH +'/'+CUSTOM_MODEL_NAME} --output_directory {EXPORTED_MODELS}/{OUTPUT_MODEL}\n",
        "# !python exporter_main_v2.py --input_type image_tensor --pipeline_config_path ./models/[name_of_pre-trained-model you downloaded]/pipeline.config --trained_checkpoint_dir ./models/[name_of_pre-trained-model_you_downloaded]/ --output_directory ./exported-models/my_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqt8HidxzK2J"
      },
      "source": [
        "#  **7.Testing  Model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAQWLOON4dZt"
      },
      "source": [
        "We have finished training and exporting our model. It's time to test our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz2jiOgJ4mUK"
      },
      "outputs": [],
      "source": [
        "# 5.1 Loading the saved_model\n",
        "\n",
        "#Loading the saved_model\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "PATH_TO_SAVED_MODEL= EXPORTED_MODELS+'/'+OUTPUT_MODEL+'/saved_model'\n",
        "\n",
        "print('Loading model...', end='')\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn=tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CEK MODEL\n",
        "PATH_TO_SAVED_MODEL"
      ],
      "metadata": {
        "id": "VNLbVl2dnTsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX--5tHy4-S1"
      },
      "outputs": [],
      "source": [
        "# 5.2 Testing the Model.\n",
        "\n",
        "#Loading the label_map\n",
        "category_index=label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+\"/label_map.pbtxt\",use_display_name=True)\n",
        "\n",
        "#category_index=label_map_util.create_category_index_from_labelmap([path_to_label_map],use_display_name=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UURD_H_c5grh"
      },
      "outputs": [],
      "source": [
        "#Loading the image\n",
        "img=[\n",
        "      IMAGE_PATH+'/image_testing_rondi/SENIN/image_RONDI_215.jpg',\n",
        "      IMAGE_PATH+'/image_testing_rondi/SELASA/image_RONDI_269.jpg',\n",
        "      IMAGE_PATH+'/image_testing_rondi/RABU/image_RONDI_233.jpg',\n",
        "      IMAGE_PATH+'/image_testing_rondi/KAMIS/image_RONDI_2192.jpg',\n",
        "      IMAGE_PATH+'/image_testing_rondi/JUMAT/image_RONDI_2260.jpg',\n",
        "      IMAGE_PATH+'/image_testing_rondi/SABTU/image_RONDI_2321.jpg',\n",
        "      IMAGE_PATH+'/image_testing_rondi/MINGGU/image_RONDI_2356.jpg',\n",
        "     ]\n",
        "print(img)\n",
        "\n",
        "#list containing paths of all the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swO5JcDurLne"
      },
      "source": [
        "## 5.1.Show image testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR5KWQ7qrAhu"
      },
      "outputs": [],
      "source": [
        "#Step 16- show image testing\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "for image_path in img:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "    image_np=load_image_into_numpy_array(image_path)\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    %matplotlib inline\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np)\n",
        "    print('Done')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKA0QJBGrUdG"
      },
      "source": [
        "## 5.2 Show Deteksi on image "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {IMAGE_PATH}/output_deteksi_image\n",
        "dir_img_detection =str(NUM_STEPS)\n",
        "!mkdir {dir_img_detection}"
      ],
      "metadata": {
        "id": "1pDqfqZnQNj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 17- Running the Inference.\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "for image_path in img:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "    image_np=load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor=tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor=input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections=detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections=int(detections.pop('num_detections'))\n",
        "    detections={key:value[0,:num_detections].numpy()\n",
        "                   for key,value in detections.items()}\n",
        "    detections['num_detections']=num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes']=detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    image_np_with_detections=image_np.copy()\n",
        "       \n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np_with_detections,\n",
        "          detections['detection_boxes'],\n",
        "          detections['detection_classes'],\n",
        "          detections['detection_scores'],\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          max_boxes_to_draw=1,     #max number of bounding boxes in the image\n",
        "          min_score_thresh=.3,      #min prediction threshold\n",
        "          agnostic_mode=False,\n",
        "          line_thickness=3,\n",
        "          keypoint_edges=4,\n",
        "          )\n",
        "    \n",
        "    %matplotlib inline\n",
        "    name= os.path.basename(image_path)\n",
        "    plt.figure(figsize=[10,10],dpi=100)\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    cv2.imwrite(IMAGE_PATH+'/output_deteksi_image/'+dir_img_detection+'/'+name, image_np_with_detections)\n",
        "    print('Done')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bOExaMkg9QIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "srkIMr0mP3qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAQv8465ZGsP"
      },
      "source": [
        "Acknowledgements:\n",
        "\n",
        "Huge Thanks to [Lyudmil Vladimirov](http://pcwww.liv.ac.uk/~sglvladi/) for allowing me to use some of the content from their amazing [TensorFlow 2 Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/index.html) for Local Machines!\n",
        "\n",
        "Link to their [GitHub Repository](https://github.com/sglvladi/TensorFlowObjectDetectionTutorial)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6UYLT5ogwq_"
      },
      "source": [
        "# **8.TESTING WITH RECORD VIDEO**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_Cj-PbsdST7"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import display, Javascript,HTML\n",
        "# from google.colab.output import eval_js\n",
        "# from base64 import b64decode\n",
        "\n",
        "# def record_video(filename):\n",
        "#   js=Javascript(\"\"\"\n",
        "#     async function recordVideo() {\n",
        "#       const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
        "#       const div = document.createElement('div');\n",
        "#       const capture = document.createElement('button');\n",
        "#       const stopCapture = document.createElement(\"button\");\n",
        "      \n",
        "#       capture.textContent = \"Start Recording\";\n",
        "#       capture.style.background = \"yellow\";\n",
        "#       capture.style.color = \"black\";\n",
        "\n",
        "#       stopCapture.textContent = \"Stop Recording\";\n",
        "#       stopCapture.style.background = \"red\";\n",
        "#       stopCapture.style.color = \"white\";\n",
        "#       div.appendChild(capture);\n",
        "\n",
        "#       const video = document.createElement('video');\n",
        "#       const recordingVid = document.createElement(\"video\");\n",
        "#       video.style.display = 'block';\n",
        "\n",
        "#       const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n",
        "    \n",
        "#       let recorder = new MediaRecorder(stream, options);\n",
        "#       document.body.appendChild(div);\n",
        "#       div.appendChild(video);\n",
        "\n",
        "#       video.srcObject = stream;\n",
        "#       video.muted = true;\n",
        "\n",
        "#       await video.play();\n",
        "\n",
        "#       google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "#       await new Promise((resolve) => {\n",
        "#         capture.onclick = resolve;\n",
        "#       });\n",
        "#       recorder.start();\n",
        "#       capture.replaceWith(stopCapture);\n",
        "\n",
        "#       await new Promise((resolve) => stopCapture.onclick = resolve);\n",
        "#       recorder.stop();\n",
        "#       let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
        "#       let arrBuff = await recData.data.arrayBuffer();\n",
        "      \n",
        "#       // stop the stream and remove the video element\n",
        "#       stream.getVideoTracks()[0].stop();\n",
        "#       div.remove();\n",
        "\n",
        "#       let binaryString = \"\";\n",
        "#       let bytes = new Uint8Array(arrBuff);\n",
        "#       bytes.forEach((byte) => {\n",
        "#         binaryString += String.fromCharCode(byte);\n",
        "#       })\n",
        "#     return btoa(binaryString);\n",
        "#     }\n",
        "#   \"\"\")\n",
        "#   try:\n",
        "#     display(js)\n",
        "#     data=eval_js('recordVideo({})')\n",
        "#     binary=b64decode(data)\n",
        "#     with open(filename,\"wb\") as video_file:\n",
        "#       video_file.write(binary)\n",
        "#     print(f\"Finished recording video at:{filename}\")\n",
        "#   except Exception as err:\n",
        "#     print(str(err))\n",
        "\n",
        "# # Set path to save video here\n",
        "# video_path = IMAGE_PATH+\"/video/input/rondi_record.mp4\"\n",
        "# record_video(video_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq441Hr5sF6q"
      },
      "source": [
        "## 8.1 DETEKSI HASIL VIDEO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsCcuddceTkT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import time\n",
        "# import tensorflow as tf\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# # from utils import label_map_util\n",
        "# from PIL import Image\n",
        "# from google.colab.patches import cv2_imshow\n",
        "# from object_detection.utils import label_map_util\n",
        "# from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "# from IPython.display import HTML\n",
        "# from base64 import b64encode\n",
        "\n",
        "# #Path to saved model  \n",
        "\n",
        "# PATH_TO_SAVED_MODEL = EXPORTED_MODELS+'/'+OUTPUT_MODEL+'/saved_model'\n",
        "\n",
        "# # Load label map and obtain class names and ids\n",
        "# #label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "# category_index=label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+\"/label_map.pbtxt\",use_display_name=True)\n",
        "\n",
        "\n",
        "# def visualise_on_image(image, bboxes, labels, scores, thresh):\n",
        "#     (h, w, d) = image.shape\n",
        "#     for bbox, label, score in zip(bboxes, labels, scores):\n",
        "#         if score > thresh:\n",
        "#             xmin, ymin = int(bbox[1]*w), int(bbox[0]*h)\n",
        "#             xmax, ymax = int(bbox[3]*w), int(bbox[2]*h)\n",
        "\n",
        "#             cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (0,255,0), 2)\n",
        "#             cv2.putText(image, f\"{label}: {int(score*100)} %\", (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
        "#     return image\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "    \n",
        "#     # Load the model\n",
        "#     print(\"Loading saved model ...\")\n",
        "#     detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "#     print(\"Model Loaded!\")\n",
        "    \n",
        "#     # Video Capture (video_file)\n",
        "#     video_capture = cv2.VideoCapture(IMAGE_PATH+\"/video/input/rondi_record_7HARI.mp4\")\n",
        "#     start_time = time.time()\n",
        "    \n",
        "#     frame_width = int(video_capture.get(3))\n",
        "#     frame_height = int(video_capture.get(4))\n",
        "#     #fps = int(video_capture.get(5))\n",
        "#     size = (frame_width, frame_height)\n",
        "    \n",
        "#     #Initialize video writer\n",
        "#     result = cv2.VideoWriter(IMAGE_PATH+\"/video/output/rondi_record_detection.avi\", cv2.VideoWriter_fourcc(*'MJPG'),15, size)\n",
        "\n",
        "#     while True:\n",
        "#       ret, frame = video_capture.read()\n",
        "#       if not ret:\n",
        "#           print('Unable to read video / Video ended')\n",
        "#           break\n",
        "    \n",
        "#       frame = cv2.flip(frame, 1)\n",
        "#       image_np = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#       # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "#       # The model expects a batch of images, so also add an axis with `tf.newaxis`.\n",
        "#       input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
        "\n",
        "#       # Pass frame through detector\n",
        "#       detections = detect_fn(input_tensor)\n",
        "\n",
        "#       # Set detection parameters\n",
        "\n",
        "#       score_thresh = 0.4   # Minimum threshold for object detection\n",
        "#       max_detections = 1\n",
        "\n",
        "#       # All outputs are batches tensors.\n",
        "#       # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "#       # We're only interested in the first num_detections.\n",
        "#       scores = detections['detection_scores'][0, :max_detections].numpy()\n",
        "#       bboxes = detections['detection_boxes'][0, :max_detections].numpy()\n",
        "#       labels = detections['detection_classes'][0, :max_detections].numpy().astype(np.int64)\n",
        "#       labels = [category_index[n]['name'] for n in labels]\n",
        "\n",
        "#       # Display detections\n",
        "#       visualise_on_image(frame, bboxes, labels, scores, score_thresh)\n",
        "\n",
        "#       end_time = time.time()\n",
        "#       fps = int(1/(end_time - start_time))\n",
        "#       start_time = end_time\n",
        "#       cv2.putText(frame, f\"FPS: {fps}\", (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 1)\n",
        "#       #cv2_imshow(frame)\n",
        "      \n",
        "#       #Write output video\n",
        "#       result.write(frame)\n",
        "\n",
        "#     video_capture.release()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deKjfx7VsbV0"
      },
      "source": [
        "## 8.2 CONVERSI TO WEBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f5N27idfhGA"
      },
      "outputs": [],
      "source": [
        "# %cd {IMAGE_PATH}/video/output\n",
        "# !ffmpeg -i ./rondi_record_detection.avi -vcodec vp9 ./rondi_record_detection.webm -y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0DfIQrlgP-8"
      },
      "outputs": [],
      "source": [
        "# # Displaying the Drawing Result\n",
        "# %cd {IMAGE_PATH}/video/output\n",
        "\n",
        "# import io\n",
        "# from base64 import b64encode\n",
        "# from IPython.display import HTML\n",
        "\n",
        "# with  io.open('rondi_record_detection.webm','r+b') as f:\n",
        "#     mp4 = f.read()\n",
        "# data_url = \"data:video/webm;base64,\" + b64encode(mp4).decode()\n",
        "# HTML(\"\"\"\n",
        "# <video width=200 controls>\n",
        "#       <source src=\"%s\" type=\"video/webm\">\n",
        "# </video>\n",
        "# \"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwOXQtgudTYn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygPgMC1LlcV3"
      },
      "source": [
        "# **9.COMPRESS PROJECT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k3JIDLpqyMq"
      },
      "outputs": [],
      "source": [
        "# %cd /content/gdrive/MyDrive\n",
        "# !zip -r {NEW_folder_work}_{NUM_STEPS}\"TRAIN_HARI.zip\" {NEW_folder_work}\n",
        "# # !unzip \"/content/gdrive/MyDrive/\"{NEW_folder_work}\"_40K_TRAIN.zip\" -d \"/content/gdrive/MyDrive/\"{NEW_folder_work}\n",
        "# # !mv /content/gdrive/MyDrive/{NEW_folder_work}/{NEW_folder_work} /content/gdrive/MyDrive/{NEW_folder_work}_COPY"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "miqMSoFhziVS",
        "1Isizxnjz7GH",
        "9GlkGq-wG_XM",
        "OL2bbe8nhDc6",
        "pDZd_WY_gLJ3",
        "swO5JcDurLne"
      ],
      "machine_shape": "hm",
      "name": "8.BISINDO_HARI_97.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "ee6ef56facda7503055c4941e2c2083c4bcc9ecb08a66ac58f56d3b05ea5e5fc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}